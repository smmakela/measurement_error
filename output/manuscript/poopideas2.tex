\documentclass[10pt,a4paper]{article}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{tabularx}
\usepackage{graphicx,setspace}
\usepackage[justification = centering]{caption}
\usepackage{fullpage}
\usepackage[space]{grffile}
\usepackage[titletoc,toc,title]{appendix}
\usepackage[round]{natbib}
\usepackage{multirow}
\usepackage{color}
\newcommand\notype[1]{\unskip}
%\graphicspath{{/Users/susanna/Dropbox/PhD/Research/IndiaOD/Figures/}}
\usepackage{multicol}

\newcommand\E{\mathbb{E}}
\newcommand\R{\mathbb{R}}
\newcommand\half{\frac{1}{2}}
\newcommand\muhat{\hat{\mu}}
\newcommand\Siginv{\Sigma^{-1}}
\newcommand{\betahat}{\hat{\beta}}
\newcommand{\one}{\mathbf{1}}
\newcommand{\oneT}{\mathbf{1}^T}
\newcommand*{\red}{\textcolor{red}}

\title{Measurement Error}
\author{Susanna Makela}

\onehalfspacing

\begin{document}
\maketitle

\section*{Quick and Dirty}
\subsection*{Generating finite population data}
Set the values of the hyperparameters and parameters to be:

\begin{center}
	\begin{tabular}{cc} 
		{$\!\begin{aligned}
			J &= 5000 \\
			\mu &= 0 \\
			\beta &= 4 \\
			\tau &= 1 \\
			\sigma_y &= 1 \\ \end{aligned}$} & {$\!\begin{aligned}
			(N^{low}, N^{high}) &= (200, 500) \\
			\gamma_0 &= 1 \\
			\gamma_1 &= 2 \\
			\gamma_2 &= 1 \\
			\sigma_a &= 0.5 \end{aligned}$}
	\end{tabular}
\end{center}
The population data is then generated from:
\begin{align*}
	N_j &\sim \mathrm{Unif}(N^{low}, N^{high}) \\
	\mathrm{logit}(\rho_j) &\sim N(\mu, \tau^2) \\
	Z_i | \rho_{j[i]} &\sim \mathrm{Bern}(\rho_{j[i]}) \\
	\alpha_j | p_j &\sim N(\gamma_0 + \gamma_1 p_j + \gamma_2 u_j, \sigma_{\alpha}^2) \\
	Y_i | \alpha_{j[i]}, Z_i &\sim N(\alpha_{j[i]} + \beta Z_i, \sigma_y^2),
\end{align*}
where
\begin{align*}
	&S_j ~ \textrm{is the set of all individuals in PSU $j$, with $|S_j|=N_j$} \\
	&p_j := \frac{1}{N_j} \sum_{i \in S_j} Z_i \\
	&u_j ~\textrm{is an unobserved covariate with Corr}(u_j, \log(N_j)) = 0.75 \\
	&\quad~ \textrm{and mean}(u_j)= \mathrm{ mean(}\log(N_j).
\end{align*}

\subsection*{Sampling}
Sample $n_I$ PSUs and $n_j$ individuals within each PSU. Analogously to $S_j$, let $s_j$ be the set of individuals sampled from PSU $j$, and define $p^*_j = \frac{1}{n_j} \sum_{i \in s_j} Z_i$. 

\subsection*{Models we fit}
We have four different models we can fit depending on whether we assume the $N_j$'s are known to the analyst and whether we are accounting for measurement error.

%In all four cases, the first level is
%\[
%	Y_i \sim N(\alpha_{j[i]} + \beta Z_i, \sigma_y^2).
%\]
%The models for $\alpha_j$ are listed in Table \ref{table:models}. We also define
%\begin{align*}
%	p^*_j &= \frac{1}{n_j} \sum_{i \in s_j} Z_i 	
%\end{align*}

\begin{table}[h!]
	\centering
	\begin{tabular}[t]{l|ll}
				& $N_j$ unknown & $N_j$ known \\
		\hline \\
		Naive model & $Y_i \sim N(\alpha_{j[i]} + \beta Z_i, \sigma_y^2)$ & $Y_i \sim N(\alpha_{j[i]} + \beta Z_i, \sigma_y^2)$ \\[1ex]
					& $\alpha_j \sim N(\gamma_0 + \gamma_1 p^*_j, \sigma_{\alpha}^2)$ & 
					$\alpha_j \sim N(\gamma_0 + \gamma_1 p^*_j + \gamma_2 \log(N_j), \sigma_{\alpha}^2)$ \\
		\\
		Full model & $Y_i \sim N(\alpha_{j[i]} + \beta Z_i, \sigma_y^2)$ & $Y_i \sim N(\alpha_{j[i]} + \beta Z_i, \sigma_y^2)$ \\ [1ex]
					& $\alpha_j \sim N(\gamma_0 + \gamma_1 \rho_j, \sigma_{\alpha}^2)$ &
					$\alpha_j \sim N(\gamma_0 + \gamma_1 \rho_j + \gamma_2 \log(N_j), \sigma_{\alpha}^2)$ \\ [1ex]
					& $Z_i \sim \mathrm{Bern}(\rho_{j[i]})$ & $Z_i \sim \mathrm{Bern}(\rho_{j[i]})$
	\end{tabular}
	\caption{Summary of models.}
	\label{table:models}
\end{table}

%\begin{center}
%%	\begin{tabularx}{\linewidth}{XXX}
%	\begin{tabular}[t]{l|cc}
%		& $N_j$ unknown & $N_j$ known \\
%		\hline \\
%		Naive model & {$\!\begin{aligned}
%							%Y_i &\sim N(\alpha_{j[i]} + \beta Z_i, \sigma_y^2) \\
%							\alpha_j &\sim N(\gamma_0 + \gamma_1 p^*_j, \sigma_{\alpha}^2) \end{aligned}$} & 
%					{$\!\begin{aligned}
%							%Y_i &\sim N(\alpha_{j[i]} + \beta Z_i, \sigma_y^2) \\
%							\alpha_j &\sim N(\gamma_0 + \gamma_1 p^*_j + \gamma_2 \log(N_j), \sigma_{\alpha}^2) \end{aligned}$} \\
%		\\
%		Full model & {$\!\begin{aligned}
%							%Y_i &\sim N(\alpha_{j[i]} + \beta Z_i, \sigma_y^2) \\
%							\alpha_j &\sim N(\gamma_0 + \gamma_1 \rho_j, \sigma_{\alpha}^2) \\
%							Z_i &\sim \mathrm{Bern}(\rho_{j[i]}) \end{aligned}$} & 
%					{$\!\begin{aligned}
%							%Y_i &\sim N(\alpha_{j[i]} + \beta Z_i, \sigma_y^2) \\
%							\alpha_j &\sim N(\gamma_0 + \gamma_1 \rho_j + \gamma_2 N_j, \sigma_{\alpha}^2) \\
%							Z_i &\sim \mathrm{Bern}(\rho_{j[i]}) \end{aligned}$} 
%	\end{tabular}
%\end{center}


\begin{itemize}
	\item \textbf{``Naive" model.} This model ignores measurement error and assumes that $p^*_j$ is a good enough approximation for $p_j$.
	
		\textbf{$N_j$'s known.}
			\begin{align*}
				Y_i | \alpha_{j[i]}, Z_i &\sim N(\alpha_{j[i]} + \beta Z_i, \sigma_y^2) \\
				\alpha_j | p^*_j &\sim N(\gamma_0 + \gamma_1 p^*_j + \gamma_2 \log(N_j), \sigma_{\alpha}^2) \\
			\end{align*}

		\textbf{$N_j$'s unknown.}
			\begin{align*}
				Y_i | \alpha_{j[i]}, Z_i &\sim N(\alpha_{j[i]} + \beta Z_i, \sigma_y^2) \\
				\alpha_j | p^*_j &\sim N(\gamma_0 + \gamma_1 p^*_j + \gamma_2 \log(N_j), \sigma_{\alpha}^2) \\
			\end{align*}
						
	\item \textbf{``Full" model.} This model accounts for measurement error. Here we make the simplification of using the superpopulation parameter $\rho_j$ in place of the finite population parameter $p_j$ in the model for $\alpha_j$. This approximation is very good in the context of our simulation. By the Central Limit Theorem, $(p_j - \rho_j) \xrightarrow[n \rightarrow \infty]{d} N(0, \rho_j (1 - \rho_j)/N_j)$. The values of $N_j$ that we are using are 200 or greater, so the normal approximation is reasonable, and the variance of $p_j$ around $\rho_j$ is therefore at most $.5*.5/200=0.00125$. This is equivalent to a standard deviation of $\sqrt{0.00125}=0.035$. Assuming the normal approximation holds, we can then say that $\mathbb{P}(|p_j - \rho_j| < 0.07) = 0.95$ -- that is, the observed $p_j$'s are within $0.07$ of $\rho_j$ with 95\% probability.
	
		\textbf{$N_j$'s known.}
			\begin{align*}
				Y_i | \alpha_{j[i]}, Z_i &\sim N(\alpha_j + \beta Z_i, \sigma_y^2) \\
				\alpha_j | \rho_j &\sim N(\gamma_0 + \gamma_1 \rho_j + \gamma_2 \log(N_j), \sigma_{\alpha}^2) \\
				Z_i | \rho_{j[i]} &\sim \mathrm{Bern}(\rho_{j[i]})
			\end{align*}	
			
		\textbf{$N_j$'s unknown.} 
			\begin{align*}
				Y_i | \alpha_{j[i]}, Z_i &\sim N(\alpha_{j[i]}	 + \beta Z_i, \sigma_y^2) \\
				\alpha_j | \rho_j &\sim N(\gamma_0 + \gamma_1 \rho_j, \sigma_{\alpha}^2) \\
				Z_i &\sim Bern(\rho_{j[i]})
			\end{align*}
\end{itemize}


\section*{More Detail}
\subsection*{The population and the sample}
Consider a population consisting of $J$ primary sampling units (PSUs). Each of the $j = 1, \ldots, J$ PSUs consists of $N_j$ individuals in a particular target demographic group, with a total population size of $N = \sum_{j=1}^J N_j$. A survey is conducted that samples $n_I$ PSUs and $n_j$ individuals in each PSU. Let $S_j$ denote the set of all individuals in the target demographic group in PSU $j$ and let $s_j$ denote the set of \textit{sampled} individuals in PSU $j$ so that $|S_j| = N_j$ and $|s_j| = n_j$.

The survey collects information on $n = \sum_{j=1}^{n_I} n_j$ individuals. Specifically, the survey data consist of an individual-level disease status outcome $Y_i$ and a binary individual-level covariate $Z_i$. The binary covariate $Z_i$ is the presence/absence of a risk factor for individual $i$ and is assumed to be drawn from a Bernoulli distribution with parameter $\rho_{j[i]} \in [0,1]$ (the notation $j[i]$ denotes the area $j$ to which individual $i$ belongs):
\[
	Z_i | \rho_{j[i]} \overset{ind}{\sim} \textrm{Bern}(\rho_{j[i]}).
\]
Thus, $\rho_j$ is the latent prevalence of or propensity for the risk factor $Z$ in PSU $j$. We assume that it has a normal distribution (on the logit scale):
\[
	\textrm{logit}(\rho_j) \sim N(\mu, \tau^2).
\]
%\red{I feel like I need to say something else about $\rho_j$ here...}

In contrast, the true unobserved prevalence of $Z$ in PSU $j$ is
%\red{not sure about the word ``true" here -- I tried ``actual" also, but either way I'm worried about causing confusion between the roles and meanings of $\rho_j$ and $p_j$ and the uses of the words ``latent", ``underlying", ``true", ``unobserved", etc.}
\[
	p_j = \frac{1}{N_j} \sum_{i \in S_j} Z_i,
\]
from which it follows that the true underlying number of individuals in the PSU with the risk factor, $T_j = \sum_{i \in S_j} Z_i$, is distributed as
\[
	T_j | \rho_j \sim \mathrm{Bin}(N_j, \rho_j).
\]

Under this data generating mechanism, people moving in and out of area $j$ will change the unobserved finite population prevalence $p_j$ (since they will cause $N_j$ to change), but they won't affect the superpopulation prevalence/propensity $\rho_j$. This distinction between the latent propensity $\rho_j$ for the risk factor and the underlying prevalence $p_j$ is useful because in reality, we know that it is the $Z_i$'s that determine $p_j$, not the other way around.

%(As a side note, we can imagine that in some contexts, the propensity for having the risk factor depends on the composition of the population in area $j$. For example, if the risk factor $Z_i$ is whether an individual has high blood pressure or not, we would expect $\rho_j$ to be higher in areas with more older people and lower in areas with more younger, active people. In this scenario, the composition of the specific $N_j$ people who make up the population of area $j$ can be thought of as \textit{determining} the prevalence $\rho_j$ of the risk factor.)


%\red{I'm not sure what it means to think about $X_j$ as a superpopulation vs a finite population proportion. As I've defined it, it's the proportion of the $N_j$ people in PSU $j$ who have the risk factor (e.g. the proportion of smokers). But if I'm thinking about the PSUs as a random sample from a superpopulation of PSUs, how does that change how I think about $X_j$?}

Because we only sample $n_j < N_j$ individuals in each PSU, we only observe the imperfectly measured prevalence $p^*_j$ instead of the true prevalence $p_j$, where
\[
	p^*_j = \frac{1}{n_j} \sum_{i \in s_j} Z_i.
\]
The observed number of individuals with the risk factor is $T^*_j = \sum_{i \in s_j} Z_i$. The distribution of $T^*_j$ is hypergeometric with parameters $n_j$, $T_j$, and $N_j$: we have a PSU with $N_j$ individuals, $T_j = \sum_{i \in S_j} Z_i$ of whom have the risk factor of interest, and in a sample of $n_j$ individuals \textit{without replacement}, we want to know the number $T^*_j$ of them with the risk factor.

For now, we assume that the outcome $Y_i$ is continuous and normally distributed. Specifically, we assume that
\begin{align*}
	Y_i | \alpha_{j[i]}, Z_i &\sim N(\alpha_{j[i]} + \beta Z_i, \sigma_y^2) \\
	\alpha_j | p_j, u_j &\sim N(\gamma_0 + \gamma_1 p_j + \gamma_2 u_j, \sigma_{\alpha}^2),
\end{align*}
where $u_j$ is an unobserved covariate such that $\mathbb{E}(u_j) = \log(N_j)$ and $\mathrm{Corr}(u_j, log(N_j)) = 0.75$. That is, the (log of the) PSU population sizes $N_j$ is correlated with a covariate $u_j$ that is predictive of the outcome $Y_i$. In many health applications, this is a realistic assumption: village size may be correlated with health determinants such as access to major roads, quality of local health facilities, or geography (e.g. less malaria-prone highlands or more fertile agricultural areas)  \red{citations for this???}.

This model assumes that it is the true finite population prevalence $p_j$ rather than $\rho_j$ that drives the variation in PSU-specific intercepts. In other words, the average value of $Y_i$ in PSU $j$ among individuals without the risk factor is $\mathbb{E}[Y_i | Z_i = 0] = \gamma_0 + \gamma_1 p_j + \gamma_2 \log(N_j) = \gamma_0 + \gamma_1 \frac{1}{N_j} \sum_{i \in S_j} Z_i + \gamma_2 \log(N_j)$.
%\red{omg totally turned around now over this. does it matter?? something about ``contextual" and ``direct" effects as in Gelman (2006)?}

%Is this reasonable? We are assuming that $Z_i$ is determined by $\rho_{j[i]}$. $Y_i$ is determined by $Z_i$ and a PSU effect $\alpha_{j[i]}$. But what should we assume $\alpha_j$ is determined by? To answer this, we need to think about the meaning of $\alpha_j$. It is the average outcome $Y$ in area $j$ when $Z=0$ (ie, the risk factor is not present). So, do we think that this mean is determined by $\rho_j$ or $p_j$? I think it makes more sense to think of it in terms


%%%%
% need to think about how to formulate the disease/measurement/exposure models here
However, we do not observe $p_j$ and can only use the imperfect surrogate $p^*_j$. In epidemiology, measurement error models are often broken down into three submodels \citep{richardson_gilks}. The first is a disease model that describes the relationship between the outcome or disease status $Y$ and the true risk factor $p$. (Other risk factors $C$, assumed to be accurately measured, can also be included in this model, but we ignore them for now.) Next is a measurement model that relates the true risk factor $p$ to the mismeasured surrogate $p^*$, and last is the exposure model that describes the distribution of the true risk factor $p$ in the population.

In these submodels, the risk factor $p$ and the disease status $Y$ are both measured at the individual level. In particular, the measurement error applies to an individual-level risk factor. In our case, however, the individual-level risk factor $Z_i$ is measured accurately, but the PSU-level prevalence $p_j$ is not because we only observe $Z_i$ for $n_j$ out of $N_j$ individuals in each PSU. In our scenario, the disease, measurement, and exposure models are as follows:

\begin{align}
	\textrm{disease model:} \quad \quad &Y_i | Z_i, \alpha_{j[i]} \sim N(\alpha_{j[i]} + \beta Z_i, \sigma_y^2) \label{disease} \\
	&\alpha_j | p_j, u_j \sim N(\gamma_0 + \gamma_1 p_j + \gamma_2 u_j, \sigma_{\alpha}^2) \notag\\
	&Z_i | \rho_{j[i]} \sim \textrm{Bern}(\rho_{j[i]}) \notag\\
	\textrm{measurement model:}\quad \quad	&T^*_j | n_j, T_j, N_j \sim \textrm{Hypergeom}(n_j, T_j, N_j) \label{measurement} \\
	& T_j | \rho_j \sim \textrm{Bin}(N_j, \rho_j) \notag\\
	\textrm{exposure model:} \quad \quad &\textrm{logit}(\rho_j) \sim N(\mu, \tau^2) \label{exposure}
\end{align}


%NOTE to self: could calculate the marginal distribution of $T^*_j$? Then would have dist of $T^*_j$ in terms of $n_j$, $N_j$, and $\rho_j$. Is this useful? Could we somehow use it in the case where we don't know $N_j$? NO obviously not, because the dist is in terms of $N_j$!!s

%
%These submodels make several assumptions about the relationship between disease status $Y$ and the true and mismeasured risk factor prevalences $p$ and $p^*$.
%%These submodels arise from the assumptions of conditional independence between disease status and surrogate mismeasured risk factors given unobserved true risk factors.
%Specifically, we assume that the measurement error is nondifferential \citep{gustafson_book}, meaning that conditional on the true risk factor prevalence $X_{j[i]}$, the surrogate $X^*_{j[i]}$ and the outcome $Y_i$ are independent for all individuals $i$ and corresponding PSUs $j[i]$ \red{ughhhh}. That is, the measurement error itself carries no information about the outcome. We also assume that, conditional on the true risk factor $X_j$, the surrogates $X^*_j$ are independent for all $j = 1, \ldots, J$ PSUs. \red{need to think more carefully about these assumptions as they're given in \cite{richardson_gilks} in this context.} We can then write the joint distribution of $\mathbf{Y} = (Y_1, \ldots, Y_N)$, $\mathbf{X} = (X_1, \ldots, X_J)$, and $\mathbf{Z} = (Z_1, \ldots, Z_N)$ as
%\[
%	\prod_j \left[ p(X_j) \prod_i \left( p(Z_i | X_{j[i]}) p(Y_i | Z_i, X_{j[i]}) \right) \right].
%\]
%\red{add the $\alpha_j$'s to the last term}

%\red{Of course, this also assumes that, conditional on the $X_j$'s, the $Y_i$'s in different PSUs are independent. This is reasonable, but if we want there to be spatial correlation in $Y_i$ then we'd have to change things. Also, I think I should talk about how exchangeability works into this scenario but not sure I understand it adequately...}

\section*{Some simulations}

\subsection*{Generating finite population data}\label{popdata}
Set parameters/hyperparameters:
\begin{center}
	\begin{tabular}{cc} 
		{$\!\begin{aligned}
			J &= 5000 \\
			\mu &= 0 \\
			\beta &= 4 \\
			\tau &= 1 \\
			\sigma_y &= 1 \\ \end{aligned}$} & {$\!\begin{aligned}
			(N^{low}, N^{high}) &= (200, 500) \\
			\gamma_0 &= 1 \\
			\gamma_1 &= 2 \\
			\gamma_2 &= 1 \\
			\sigma_a &= 0.5 \end{aligned}$}
	\end{tabular}
\end{center}
Generate population data:
\begin{enumerate}
	\item Draw PSU population sizes $N_j$ from $N_j \sim \mathrm{Unif}(N^{low}, N^{high})$.
	\item Draw the superpopulation prevalences $\rho_j$ from $\mathrm{logit}(\rho_j) \sim N(\mu, \tau^2)$.
	\item Set individual-level risk factor to present/absent according to $Z_i | \rho_{j[i]} \sim \mathrm{Bern}(\rho_j)$.
	\item Calculate finite population prevalence $p_j = 1/N_j \sum_{i=1}^{N_j} Z_i$.
	\item Generate $\mathbf{u} = (u_1, \ldots, u_J)$ such that $\mathrm{Corr}(\mathbf{u}, \mathbf{\log(N)}) = 0.75$ ($\mathbf{\log(N)} = (\log(N_1), \ldots, \log(N_J))$) and $\overline{\mathbf{u}} = \overline{\mathbf{\log(N)}}$.
	\item Draw PSU-specific intercepts from $\alpha_j | p_j \sim N(\gamma_0 + \gamma_1 p_j + \gamma_2 \log(u_j), \sigma_{\alpha}^2)$.
	\item Draw individual-level outcome from $Y_i | \alpha_{j[i]}, Z_i \sim N(\alpha_{j[i]} + \beta Z_i, \sigma_y^2)$.
\end{enumerate}

\subsection*{Sampling}\label{sampling}
We then sample from the population:
\begin{enumerate}
	\item Sample $n_I$ out of $J$ PSUs with probability proportional to size (PPS).
	\item From each sampled PSU, take a simple random sample (SRS) of $n_j$ individuals.
\end{enumerate}
We use $n_I \in \{10, 50, 100, 500\}$ and $n_j \in \{2, 20, 200\}$ for all $j$. In this way, the sample is self-weighting \red{reference?? ask shira}

\subsection*{Models}\label{models}
We fit two types of models to the data.
\begin{itemize}
	\item \textbf{``Naive" model.} This model ignores measurement error and assumes that $p^*_j$ is a good approximation for $p_j$.
		\begin{align*}
			Y_i | \alpha_{j[i]}, Z_i &\sim N(\alpha_j + \beta Z_i, \sigma_y^2) \\
			\alpha_j | p_j &\sim N(\gamma_0 + \gamma_1 p^*_j, \sigma_{\alpha}^2) \\
		\end{align*}
	\item \textbf{``Full" model.} This model accounts for measurement error. Here we have two options, depending on whether the PSU population sizes $N_j$ are known or not.
	
		\textbf{$N_j$'s known.}
			\begin{align*}
				Y_i | \alpha_{j[i]}, Z_i &\sim N(\alpha_j + \beta Z_i, \sigma_y^2) \\
				\alpha_j | p_j &\sim N(\gamma_0 + \gamma_1 p_j + \gamma_2 N_j, \sigma_{\alpha}^2) \\
				Z_i | \rho_{j[i]} &\sim \mathrm{Bern}(\rho_{j[i]})
			\end{align*}	
			In this case, we can estimate the true prevalence $p_j$ with one of two methods:
			\begin{itemize}
				\item[a)] Impute the unobserved $Z_i$'s by drawing from the posterior distribution $p(\rho_j | Z_i)$ and calculate
					\[
						p_j = \frac{1}{n_j} \sum_{i \in s_j} Z_i + \frac{1}{N_j - n_j} \sum_{i \in (S_j \setminus s_j)} Z_i
					\]
				\item[b)] Sample $p_j$ by using the hypergeometric distribution for $T^*_j = n_j p^*_j$: $T^*_j \sim \mathrm{Hypergeom}(n_j, T_j, N_j)$, where $T_j = N_j \rho_j$.
			\end{itemize}
			Either way, we should also incorporate $N_j$ into the model for $\alpha_j$ because of the PPS sampling of PSUs. The PPS sampling renders the $N_j$'s part of the design information, so we need to include it to ensure that our model renders the survey design ignorable \red{cite bda}. \red{BUT, now $\gamma_1$ does not have the same interpretation as in the other models! What to do???}
	
		\textbf{$N_j$'s unknown. (to the analyst, not to the survey designer!)} 
			\begin{align*}
				Y_i | \alpha_{j[i]}, Z_i &\sim N(\alpha_{j[i]}	 + \beta Z_i, \sigma_y^2) \\
				\alpha_j | \rho_j &\sim N(\gamma_0 + \gamma_1 \rho_j, \sigma_{\alpha}^2) \\
				Z_i &\sim Bern(\rho_{j[i]})
			\end{align*}
			If the $N_j$'s are unknown, we estimate $\alpha_j$ using $\rho_j$ instead of $p_j$.
\end{itemize}

\subsection*{Replication}
We generate a total of 20 populations using the hyperparameters and parameters specified in \ref{pars}. For each population, we generate 100 samples and fit the models to all 100 samples. In this way, we obtain distributions of posterior means for the parameters of interest. These distributions are over 20 populations, so that we have averaged out sampling variability due to having used a particular sample.

\subsection*{Summary}
Our simulation study thus has three goals. First, our interest is in the effects of both $p_j$ and $Z_i$ on individual disease status $Y_i$, so we want to understand the effect of ignoring measurement error on these coefficients. Second, we want to compare the performance of the full model in the cases that the $N_j$'s are known and unknown. Finally, we want to confirm that we can estimate $p_j$ in the full model when the $N_j$'s are known using either of the methods described above.


\bibliography{pooprefs}
\bibliographystyle{plainnat}


\end{document}